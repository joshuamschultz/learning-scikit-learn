{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees are used to classify data by walking down a series of \"decisions\" that result in T/F. At the bottom of the tree you end at your node which is the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:,2:] # Just grabbing petal length and width, nothing else\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2) #max depth is how many \"decisions\" or tree nodes to move down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created and fit the model, we can visualize the rules that were created and how the decision tree works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(\n",
    "tree_clf,\n",
    "out_file='./iris_tree.dot',\n",
    "feature_names=iris.feature_names[2:],\n",
    "class_names=iris.target_names,\n",
    "rounded=True,\n",
    "filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran `dot -Tpng iris_tree.dot -o iris_tree.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Iris Tree](./img/iris_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The top line is the decsision. If true, you to the left, if false you follow the right branch.\n",
    "* *samples* show how many training instances that node applies to\n",
    "* *value* shows how many of each actual labeled target, that decision applies to\n",
    "* *gini* shows the impurity. 0 is pure (see the orange which is all 'setosa'. \n",
    "\n",
    "Gini is 1 minus the squared ratios of probability that each class is correct. \n",
    "$$ G_i = 1 - \\sum^n_{k=1} {p_{i,k}}^2$$ \n",
    "\n",
    "So for depth-2 left node (green)\n",
    "\n",
    "$$ 1 - (0/54)^2 - (49/54)^2 - (5/54)^2 = 0.168 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each class, a petal with a length of 5 and width of 1.5 would be approx 91% the 2nd (or index 1) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5,1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'versicolor'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CART funtion looks for a decision that finds the purest split at each node.\n",
    "\n",
    "It splits the dataset into 2 sections using a single feature $k$ and some threshold for the split $t_k$. It then looks to maximize purity by adjust $t_k$ (adjusted for size).\n",
    "\n",
    "So the cost function that is minimized is:\n",
    "$$ J(k,t_k) = \\frac{m_{left}}{m} G_{left} + \\frac{m_{right}}{m} G_{right} $$\n",
    "$$\n",
    "Where\n",
    "\\begin{cases}\n",
    "    G_{left/right} \\mbox{  measures the impurity of the left/right subset} \\\\\n",
    "    m_{left/right} \\mbox{  is the number of instances in the left/right subset}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the model makes decisions directly from the data without preset parameters, it usually overfits. So regularization is required.\n",
    "\n",
    "You can do this by:\n",
    "* Constraining tree depth (*max_depth*)\n",
    "* Declaring a min number of samples a node needs before splitting (*min_samples_split*)\n",
    "* Declaring a min number for a leaf to have (*min_samples_leaf*)\n",
    "* Declaring a min number for a leaf to have, but in fraction of total weighted instances (*min_weight_fraction_leaf*)\n",
    "* Declaring the max number of leaf nodes (*max_leaf_nodes*)\n",
    "* Constraining the max number of features that can be used for evaluation (*max_features*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
